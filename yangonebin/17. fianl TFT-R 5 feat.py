import os
import random
import yfinance as yf
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from sklearn.preprocessing import StandardScaler
import joblib

# --- [ 1. ì¬í˜„ì„± ê·¹ëŒ€í™” ì„¤ì •: SEED 22 ] ---
SEED = 22
os.environ['PYTHONHASHSEED'] = str(SEED)
os.environ['TF_DETERMINISTIC_OPS'] = '1'
os.environ['TF_CUDNN_DETERMINISTIC'] = '1'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# --- [ 2. TFT ì•„í‚¤í…ì²˜ ì •ì˜ ] ---

def variable_selection_network(x, units, num_features):
    feature_embeddings = []
    for i in range(num_features):
        feat = layers.Lambda(lambda x, i=i: x[:, :, i:i+1])(x)
        feature_embeddings.append(layers.Dense(units)(feat))
    combined = layers.Concatenate()(feature_embeddings)
    weights = layers.Dense(num_features, activation='softmax')(combined)
    stacked_features = layers.Lambda(lambda x: tf.stack(x, axis=2))(feature_embeddings)
    expanded_weights = layers.Reshape((-1, num_features, 1))(weights)
    weighted_features = layers.Multiply()([stacked_features, expanded_weights])
    return layers.Lambda(lambda x: tf.reduce_sum(x, axis=2))(weighted_features)

def gated_residual_network(x, units, dropout_rate=0.1):
    h = layers.Dense(units, activation='elu')(x)
    h = layers.Dense(units)(h)
    h = layers.Dropout(dropout_rate)(h)
    gate = layers.Dense(units, activation='sigmoid')(x)
    x = layers.Add()([x, layers.Multiply()([gate, h])])
    return layers.LayerNormalization()(x)

def build_beast_tft(window_size, num_features, units=64):
    inputs = Input(shape=(window_size, num_features))
    vsn = variable_selection_network(inputs, units, num_features)
    lstm = layers.LSTM(units, return_sequences=True)(vsn)
    lstm = layers.LayerNormalization()(lstm)
    attn = layers.MultiHeadAttention(num_heads=4, key_dim=units)(lstm, lstm)
    attn = layers.Add()([lstm, attn])
    attn = layers.LayerNormalization()(attn)
    grn = gated_residual_network(attn[:, -1, :], units)
    outputs = layers.Dense(1)(grn) 
    model = Model(inputs, outputs)
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='mse')
    return model

# --- [ 3. ì‹¤ì „ ì „ì²´ í•™ìŠµ ì‹¤í–‰ í•¨ìˆ˜ ] ---

def train_production_model():
    print(f"ğŸš€ [SEED 22] Beast V3: ì „ì²´ ë°ì´í„° ê¸°ë°˜ ì‹¤ì „ í•™ìŠµ ì‹œì‘ (150 Epochs)")
    
    # ë°ì´í„° ìˆ˜ì§‘ (ì‚¼ì„±ì „ì)
    df = yf.download("005930.KS", period="max", auto_adjust=True, progress=False)
    if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
    df = df[['Open', 'High', 'Low', 'Close', 'Volume']].ffill().dropna()
    
    # ë¡œê·¸ ìˆ˜ìµë¥  ê¸°ë°˜ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    feature_cols = []
    for col in df.columns:
        new_name = f'Log_Ret_{col}'
        df[new_name] = np.log((df[col] + 1e-9) / (df[col].shift(1) + 1e-9))
        feature_cols.append(new_name)
    
    # íƒ€ê²Ÿ ì„¤ì •: ë‚´ì¼ì˜ ì‹¤ì œ ìˆ˜ìµë¥ 
    df['actual_ret'] = (df['Close'].shift(-1) / df['Close']) - 1
    df = df.dropna()
    
    # StandardScaler ì ìš© ë° ì €ì¥ (FastAPI ì„œë¹™ í•„ìˆ˜í…œ)
    scaler = StandardScaler()
    df[feature_cols] = scaler.fit_transform(df[feature_cols])
    joblib.dump(scaler, 'beast_scaler.pkl')
    
    # 20ì¼ ìœˆë„ìš° ì‹œí€€ìŠ¤ ìƒì„±
    X, y = [], []
    data, ret = df[feature_cols].values, df['actual_ret'].values
    for i in range(len(df) - 20):
        X.append(data[i:i+20])
        y.append(ret[i+20-1])
    X, y = np.array(X), np.array(y)

    # ëª¨ë¸ ë¹Œë“œ ë° í•™ìŠµ
    model = build_beast_tft(X.shape[1], X.shape[2])
    
    # âœ… í•µì‹¬: ë¶„ë¦¬ ì—†ì´ ì „ì²´ í•™ìŠµ, 150 ì—í­ ì¤€ìˆ˜, ì…”í”Œ ë¹„í™œì„±í™”
    model.fit(X, y, epochs=150, batch_size=128, verbose=1, shuffle=False)
    
    # ìµœì¢… ê²°ê³¼ë¬¼ ì €ì¥
    model.save('beast_tft_full.h5')
    print("\n" + "="*50)
    print("âœ… Beast V3 (Seed 22) ì‹¤ì „ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
    print("- Model: beast_tft_full.h5")
    print("- Scaler: beast_scaler.pkl")
    print("="*50)

if __name__ == "__main__":
    train_production_model()