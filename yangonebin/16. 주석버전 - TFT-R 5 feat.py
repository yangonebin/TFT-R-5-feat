import os
import yfinance as yf
import pandas as pd
import numpy as np
import warnings
import mlflow
import mlflow.keras
import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from sklearn.preprocessing import StandardScaler
import time

# --- [ í™˜ê²½ ì„¤ì • ë° ìµœì í™”] ---
# í…ì„œí”Œë¡œìš°ì˜ ë¡œê·¸ ìˆ˜ì¤€ì„ ì¡°ì ˆí•˜ì—¬ ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ë¥¼ ìˆ¨ê¹€
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
# oneDNN ìµœì í™” ì˜µì…˜ì„ êº¼ì„œ ì—°ì‚° ìˆœì„œ ì°¨ì´ë¡œ ì¸í•œ ë¯¸ì„¸í•œ ìˆ˜ì¹˜ ë³€ë™ì„ ë°©ì§€.
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
# ë¶ˆí•„ìš”í•œ ê²½ê³ ë¥¼ ë¬´ì‹œí•˜ì—¬ í„°ë¯¸ë„ ë¡œê·¸ë¥¼ ê¹”ë”í•˜ê²Œ ìœ ì§€
warnings.filterwarnings('ignore')


# --- [1. ë°ì´í„° ìˆ˜ì§‘] ---

# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
def build_tft_data():
    """ì‚¼ì„±ì „ì ì£¼ê°€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¡œê·¸ ìˆ˜ìµë¥  ê¸°ë°˜ì˜ 5ê°œ í”¼ì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    target_stock = "005930.KS"
    # ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ì—ì„œ ì „ ê¸°ê°„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    df = yf.download(target_stock, period="max", auto_adjust=True, progress=False)
    # ë©€í‹°ì¸ë±ìŠ¤ ì»¬ëŸ¼ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.
    if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
    
    # í•µì‹¬ 5ê°œ í”¼ì²˜(ì‹œ/ê³ /ì €/ì¢…/ê±°)ë§Œ ì„ íƒí•˜ê³  ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    df = df[['Open', 'High', 'Low', 'Close', 'Volume']].ffill().dropna()
    
    feature_cols = []
    # ì£¼ê°€ì˜ ì ˆëŒ€ ìˆ˜ì¹˜ë³´ë‹¤ 'ë³€ë™ ë¹„ìœ¨'ì´ í•™ìŠµì— ìœ ë¦¬í•˜ë¯€ë¡œ ë¡œê·¸ ìˆ˜ìµë¥ ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    for col in df.columns:
        new_name = f'Log_Ret_{col}'
        df[new_name] = np.log((df[col] + 1e-9) / (df[col].shift(1) + 1e-9))
        feature_cols.append(new_name)
    
    # [Target 1] ë‚´ì¼ì˜ ì£¼ê°€ê°€ ì˜¤ë¥¼ì§€(1) ë‚´ë¦´ì§€(0) íŒë‹¨ìš© (ì‹œë®¬ë ˆì´ì…˜ìš©)
    df['target_up'] = np.where(df['Close'].shift(-1) > df['Close'], 1, 0)
    # [Target 2] ì‹¤ì œ ROI ê³„ì‚°ì„ ìœ„í•œ ë‚´ì¼ì˜ ë‹¨ìˆœ ìˆ˜ìµë¥  (ë³µë¦¬ ê³„ì‚°ìš©)
    df['actual_ret'] = (df['Close'].shift(-1) / df['Close']) - 1
    df = df.dropna()
    
    # í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ìŠ¤ì¼€ì¼ë§í•˜ì—¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ í•™ìŠµ íš¨ìœ¨ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
    for col in feature_cols:
        df[col] = StandardScaler().fit_transform(df[[col]])
    return df, feature_cols

# 2. í•™ìŠµìš© ìœˆë„ìš° ì‚¬ì´ì¦ˆ ë³€í™˜ (Inputë°ì´í„° ìƒì„±ì™„ë£Œ)
def create_sequences(df, features, window=20):
    """ê³¼ê±° 20ì¼ì¹˜ ë°ì´í„°ë¥¼ ë¬¶ì–´ í•˜ë‚˜ì˜ í•™ìŠµ ë‹¨ìœ„(Sequence)ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    X, y, r = [], [], []
    data, target, ret = df[features].values, df['target_up'].values, df['actual_ret'].values
    for i in range(len(df) - window):
        # ì…ë ¥ ë°ì´í„°: 20ì¼ê°„ì˜ ê°€ê²© ë³€ë™ íŒ¨í„´
        X.append(data[i:i+window])
        # ì •ë‹µ ë°ì´í„°: 20ì¼ì§¸ ë˜ëŠ” ë‚  ê¸°ì¤€ 'ë‚´ì¼'ì˜ ì£¼ê°€ ìƒìŠ¹ ì—¬ë¶€
        y.append(target[i+window-1])
        # ìˆ˜ìµë¥  ë°ì´í„°: ì‹¤ì œ ìì‚° ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•œ ìˆ˜ìµë¥  ê°’
        r.append(ret[i+window-1])
    return np.array(X), np.array(y), np.array(r)


# --- [2. TFT ì•„í‚¤í…ì²˜ ë¹Œë“œ] ---
# 1. model ìƒì„±ì‹œì‘

def build_beast_tft(window_size, num_features, units=64):
    """TFTì˜ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ê³¼ ìˆœí™˜ ì‹ ê²½ë§ì„ ê²°í•©í•œ ëª¨ë¸ì„ ì„¤ê³„í•©ë‹ˆë‹¤."""
    inputs = Input(shape=(window_size, num_features))
    
    # 1. ë³€ìˆ˜ ì„ íƒ: 5ê°œ í”¼ì²˜ ì¤‘ ìœ ì˜ë¯¸í•œ ì‹œê·¸ë„ì„ ë™ì ìœ¼ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤.
    vsn = variable_selection_network(inputs, units, num_features)
    
    # 2. LSTM: ì‹œê³„ì—´ì˜ ì¥ê¸°/ë‹¨ê¸° íŒ¨í„´(ë§¥ë½)ì„ íŒŒì•…í•©ë‹ˆë‹¤.
    lstm = layers.LSTM(units, return_sequences=True)(vsn)
    lstm = layers.LayerNormalization()(lstm)
    
    # 3. Multi-Head Attention: ê³¼ê±° í•œë‹¬ ì¤‘ í˜„ì¬ ê°€ê²©ì— ê°€ì¥ í° ì˜í–¥ì„ ì¤€ ë‚ ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.
    attn = layers.MultiHeadAttention(num_heads=4, key_dim=units)(lstm, lstm)
    # ì”ì°¨ ì—°ê²°(Add)ì„ í†µí•´ í•™ìŠµì˜ ì•ˆì •ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.
    attn = layers.Add()([lstm, attn])
    attn = layers.LayerNormalization()(attn)
    
    # 4. GRN: ìµœì¢… ì¶œë ¥ ì „ ë…¸ì´ì¦ˆë¥¼ í•œ ë²ˆ ë” ì œê±°í•˜ê³  íŠ¹ì§•ì„ ì •ì œí•©ë‹ˆë‹¤.
    grn = gated_residual_network(attn[:, -1, :], units)
    
    # 5. Output: ë‚´ì¼ì˜ ìˆ˜ìµë¥  ê°•ë„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” íšŒê·€(Regressor) ë…¸ë“œì…ë‹ˆë‹¤.
    outputs = layers.Dense(1)(grn) 
    
    model = Model(inputs, outputs)
    # Adam ì˜µí‹°ë§ˆì´ì €ì™€ MSE(í‰ê· ì œê³±ì˜¤ì°¨) ì†ì‹¤í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='mse')
    return model


# 2. Input -> VSN 
def variable_selection_network(x, units, num_features):
    """
    VSN ë¸”ë¡: ì…ë ¥ëœ í”¼ì²˜ë“¤ ì¤‘ í˜„ì¬ ì˜ˆì¸¡ì— ê°€ì¥ ì¤‘ìš”í•œ ë³€ìˆ˜ë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
    ì‚¼ì„±ì „ìì˜ ì‹œ/ê³ /ì €/ì¢…/ê±° ì¤‘ ë¬´ì—‡ì´ ì¤‘ìš”í•œì§€ ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ê²Œ í•©ë‹ˆë‹¤.
    """
    feature_embeddings = []
    # ê° í”¼ì²˜(ì‹œ, ê³ , ì €, ì¢…, ê±°)ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    for i in range(num_features):
        feat = layers.Lambda(lambda x, i=i: x[:, :, i:i+1])(x)
        feature_embeddings.append(layers.Dense(units)(feat))
        
    # ëª¨ë“  ì„ë² ë”©ì„ í•©ì³ì„œ ì–´ë–¤ í”¼ì²˜ê°€ ì¤‘ìš”í•œì§€ ê°€ì¤‘ì¹˜(Softmax)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    combined = layers.Concatenate()(feature_embeddings)
    weights = layers.Dense(num_features, activation='softmax')(combined)
    
    # í”¼ì²˜ ë²¡í„°ì™€ ê³„ì‚°ëœ ê°€ì¤‘ì¹˜ë¥¼ ê³±í•˜ì—¬ ì¤‘ìš”í•œ ì •ë³´ë§Œ ê°•ì¡°í•©ë‹ˆë‹¤.
    stacked_features = layers.Lambda(lambda x: tf.stack(x, axis=2))(feature_embeddings)
    expanded_weights = layers.Reshape((-1, num_features, 1))(weights)
    weighted_features = layers.Multiply()([stacked_features, expanded_weights])
    
    # ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ í”¼ì²˜ë“¤ì„ í•˜ë‚˜ë¡œ í•©ì³ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ê¹ë‹ˆë‹¤.
    return layers.Lambda(lambda x: tf.reduce_sum(x, axis=2))(weighted_features)


# 3. VSN -> LSTM -> Attn -> GRN 
def gated_residual_network(x, units, dropout_rate=0.1):
    """
    TFTì˜ í•µì‹¬ì¸ GRN ë¸”ë¡: ëª¨ë¸ì´ ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ë¥¼ í•™ìŠµí•˜ë˜, 
    í•„ìš” ì—†ëŠ” ê²½ìš°ì—ëŠ” ì‹ í˜¸ë¥¼ ê·¸ëŒ€ë¡œ í†µê³¼ì‹œì¼œ ê³¼ì í•©(Overfitting)ì„ ë°©ì§€.
    """
    # ì€ë‹‰ì¸µì„ í†µí•´ íŠ¹ì§•ì„ ì¶”ì¶œ. activation='elu'ëŠ” ê¸°ìš¸ê¸° ì†Œì‹¤ ë°©ì§€ì— íƒì›”.
    h = layers.Dense(units, activation='elu')(x)
    h = layers.Dense(units)(h)
    h = layers.Dropout(dropout_rate)(h)
    
    # GLU(Gated Linear Unit): ì •ë³´ì˜ í†µê³¼ëŸ‰ì„ ê²°ì •í•˜ëŠ” 'ìˆ˜ë¬¸' ì—­í• .
    gate = layers.Dense(units, activation='sigmoid')(x)
    # ì…ë ¥ê°’ê³¼ ë³€í™˜ëœ ê°’ì„ ë”í•´(Skip Connection) ì¸µì´ ê¹Šì–´ì ¸ë„ í•™ìŠµì´ ì˜ ë˜ê²Œ í•©ë‹ˆë‹¤.
    x = layers.Add()([x, layers.Multiply()([gate, h])])
    return layers.LayerNormalization()(x)


# --- [5. ë©”ì¸ ì‹¤í–‰ ë° ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„] ---

if __name__ == "__main__":
    # ë°ì´í„° ë¡œë“œ ë° ì‹œí€€ìŠ¤ ìƒì„±
    df, features = build_tft_data()
    X, y, r = create_sequences(df, features)
    
    # 8:2 ë¹„ìœ¨ë¡œ í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    split = int(len(X) * 0.8)
    X_train, X_test = X[:split], X[split:]
    # íƒ€ê²Ÿ(y)ì€ ì‹¤ì œ ìˆ˜ìµë¥ (r)ë¡œ ì„¤ì •í•˜ì—¬ íšŒê·€ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    y_train, y_test = r[:split], r[split:] 
    r_test = r[split:]

    # MLflow ì‹¤í—˜ì‹¤ ì„¤ì •
    mlflow.set_experiment("Samsung_SOTA_TFT_5Features_Final")
    
    roi_results, buy_counts = [], []
    
    print(f"\nğŸš€ [SOTA] TFT 5-Feature ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦ ì‹œì‘")
    print("="*60)

    # ê²°ê³¼ì˜ ì‹ ë¢°ë„ë¥¼ ìœ„í•´ ì„œë¡œ ë‹¤ë¥¸ ì‹œë“œ(Seed)ë¡œ 30íšŒ ë°˜ë³µ ì‹¤í—˜í•©ë‹ˆë‹¤.
    for seed in range(30):
        with mlflow.start_run(run_name=f"TFT_Seed_{seed}"):
            # ë‚œìˆ˜ë¥¼ ê³ ì •í•˜ì—¬ ì‹¤í—˜ ê²°ê³¼ì˜ ì¬í˜„ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.
            tf.random.set_seed(seed)
            np.random.seed(seed)
            mlflow.log_param("seed", seed)
            
            # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
            model = build_beast_tft(X.shape[1], X.shape[2])
            # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ì–¼ë¦¬ ìŠ¤í† í•‘: ê²€ì¦ ì†ì‹¤ì´ 15ë²ˆ ì •ì²´ë˜ë©´ ë©ˆì¶¥ë‹ˆë‹¤.
            es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
            
            model.fit(X_train, y_train, validation_data=(X_test, y_test), 
                      epochs=150, batch_size=128, verbose=1, callbacks=[es])
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ì£¼ê°€ ìˆ˜ìµë¥  ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
            preds = model.predict(X_test, verbose=0).flatten()
            
            # [Backtesting] 1,000ë§Œì›ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” íˆ¬ì ì‹œë®¬ë ˆì´ì…˜
            balance = 10000000
            buy_count = 0
            for i in range(len(preds)):
                # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë‚´ì¼ì˜ ìˆ˜ìµë¥ ì´ ì¡°ê¸ˆì´ë¼ë„ í”ŒëŸ¬ìŠ¤(+)ë¼ë©´ ë§¤ìˆ˜í•©ë‹ˆë‹¤.
                if preds[i] > 0: 
                    balance *= (1 + r_test[i]) # ì‹¤ì œ ê²°ê³¼ ë°˜ì˜
                    buy_count += 1
            
            # ìµœì¢… íˆ¬ì ìˆ˜ìµë¥ (ROI) ê³„ì‚°
            final_roi = ((balance - 10000000) / 10000000) * 100
            roi_results.append(final_roi)
            buy_counts.append(buy_count)
            
            # ê²°ê³¼ ì§€í‘œë¥¼ MLflowì— ê¸°ë¡í•©ë‹ˆë‹¤.
            mlflow.log_metric("final_roi", final_roi)
            mlflow.log_metric("buy_count", buy_count)
            
            print(f"[{time.strftime('%H:%M:%S')}] Seed {seed:2d} | ROI: {final_roi:8.2f}% | Buy: {buy_count:4d}")

    # --- [6. ìµœì¢… ì„±ê³¼ ë³´ê³ ì„œ ì¶œë ¥] ---
    print("\n" + "="*60)
    print(f"ğŸ† [TFT SOTA ìµœì¢… ë¦¬í¬íŠ¸]")
    print(f" - 30íšŒ í‰ê·  ROI: {np.mean(roi_results):.4f}%")
    print(f" - 30íšŒ í‰ê·  ë§¤ë§¤ íšŸìˆ˜: {np.mean(buy_counts):.2f}íšŒ")
    # 30íšŒ ì‹¤í—˜ ì¤‘ ê°€ì¥ ë†’ê²Œ í„°ì§„ ìµœê³  ìˆ˜ìµë¥ ì„ ê¸°ë¡í•©ë‹ˆë‹¤.
    print(f" - ìµœê³  ROI (Seed {np.argmax(roi_results)}): {np.max(roi_results):.2f}%")
    print("="*60)