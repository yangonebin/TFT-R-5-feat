import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

import yfinance as yf
import pandas as pd
import numpy as np
import warnings
import mlflow
import mlflow.keras
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')

# ---------------------------------------------------------
# [Helper] ë¡œê·¸ ìˆ˜ìµë¥  ê³„ì‚° í•¨ìˆ˜
# ---------------------------------------------------------
def get_log_return(series):
    return np.log((series + 1e-9) / (series.shift(1) + 1e-9))

# ==============================================================================
# [Step 1] ë°ì´í„° ìˆ˜ì§‘ ë° 14ê°œ í”¼ì²˜ ë§ˆíŠ¸ êµ¬ì¶• (ë¡œê·¸ ìˆ˜ìµë¥  ê¸°ë°˜)
# ==============================================================================
def build_data_mart_v4():
    print("="*60)
    print(" [Step 1] 14ê°œ í”¼ì²˜ ë³µì› ë° ë¡œê·¸ ìˆ˜ìµë¥  ë³€í™˜")
    print("="*60)
    
    target_stock = "005930.KS" 
    macro_symbols = { "USD_KRW": "KRW=X", "Gold": "GC=F", "Interest_Rate": "^TNX" }

    # 1. ì£¼ê°€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    df = yf.download(target_stock, period="max", auto_adjust=True, progress=False)
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.get_level_values(0)
    
    # 2. ê±°ì‹œ ê²½ì œ ë°ì´í„° í†µí•©
    for name, symbol in macro_symbols.items():
        macro = yf.download(symbol, period="max", auto_adjust=True, progress=False)
        if isinstance(macro.columns, pd.MultiIndex):
            macro.columns = macro.columns.get_level_values(0)
        df[name] = macro['Close']

    df = df.ffill()

    # 3. ì¼ëª©ê· í˜•í‘œ í”¼ì²˜ ìƒì„± (ë¡œê·¸ ë³€í™˜ ì „ ì›ë³¸ ê°€ê²© ê¸°ì¤€ ê³„ì‚°)
    nine_high = df['High'].rolling(window=9).max()
    nine_low = df['Low'].rolling(window=9).min()
    df['tenkan_sen'] = (nine_high + nine_low) / 2

    twenty_six_high = df['High'].rolling(window=26).max()
    twenty_six_low = df['Low'].rolling(window=26).min()
    df['kijun_sen'] = (twenty_six_high + twenty_six_low) / 2

    df['senkou_span_a'] = ((df['tenkan_sen'] + df['kijun_sen']) / 2).shift(26)
    fifty_two_high = df['High'].rolling(window=52).max()
    fifty_two_low = df['Low'].rolling(window=52).min()
    df['senkou_span_b'] = ((fifty_two_high + fifty_two_low) / 2).shift(26)

    # íŒŒìƒ ë³€ìˆ˜: êµ¬ë¦„ëŒ€ ë‘ê»˜ ë° ê¸°ì¤€ì„  ì´ê²©ë„
    df['cloud_thickness'] = df['senkou_span_a'] - df['senkou_span_b']
    df['dist_from_kijun'] = df['Close'] - df['kijun_sen']

    # 4. ëª¨ë“  ê°€ê²©/ì§€í‘œ ë°ì´í„°ë¥¼ 'ë¡œê·¸ ìˆ˜ìµë¥ ' ë° 'ìƒëŒ€ ì§€í‘œ'ë¡œ ë³€í™˜
    feature_cols = []
    
    # ê°€ê²© ê¸°ë°˜ ì§€í‘œë“¤ ë¡œê·¸ ìˆ˜ìµë¥ í™”
    price_based_cols = [
        'Close', 'Open', 'High', 'Low', 'Volume', 
        'USD_KRW', 'Gold', 'Interest_Rate',
        'tenkan_sen', 'kijun_sen', 'senkou_span_a', 'senkou_span_b'
    ]
    
    for col in price_based_cols:
        new_name = f'Log_Ret_{col}'
        df[new_name] = get_log_return(df[col] if 'Volume' not in col else df[col].replace(0, 1))
        feature_cols.append(new_name)
    
    # ë‘ê»˜ì™€ ì´ê²©ë„ëŠ” ì´ë¯¸ ì°¨ì´ê°’ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ëª…ì¹­ë§Œ ì¶”ê°€)
    feature_cols.extend(['cloud_thickness', 'dist_from_kijun'])

    # â˜… [Target] ë‚´ì¼ì˜ ë¡œê·¸ ìˆ˜ìµë¥ 
    df['target_log_return'] = df['Log_Ret_Close'].shift(-1)
    df['actual_simple_return'] = (df['Close'].shift(-1) / df['Close']) - 1

    df = df.dropna()
    
    # 5. ìŠ¤ì¼€ì¼ë§ (MinMaxScaler)
    scalers = {}
    for col in feature_cols + ['target_log_return']:
        s = MinMaxScaler()
        df[col] = s.fit_transform(df[[col]])
        scalers[col] = s

    print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(df)}ê±´ | ì‚¬ìš© í”¼ì²˜: {len(feature_cols)}ê°œ")
    return df, feature_cols, scalers

# ==============================================================================
# [Step 2] ì‹œí€€ìŠ¤ ìƒì„± ë° ëª¨ë¸ êµ¬ì¶•
# ==============================================================================
def create_sequences(df, feature_cols, window_size=20):
    X, y_target, y_actual = [], [], []
    data_array = df[feature_cols].values
    target_array = df['target_log_return'].values
    actual_array = df['actual_simple_return'].values

    for i in range(len(df) - window_size):
        X.append(data_array[i : i + window_size])
        y_target.append(target_array[i + window_size - 1])
        y_actual.append(actual_array[i + window_size - 1])

    return np.array(X), np.array(y_target), np.array(y_actual)

def build_lstm_regression(input_shape):
    model = Sequential([
        LSTM(64, return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        LSTM(64, return_sequences=False),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dense(1) 
    ])
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# ==============================================================================
# [Main] 30íšŒ ë…ë¦½ ì‹œí–‰ (Baselineìš© ë°ì´í„° í™•ë³´)
# ==============================================================================
if __name__ == "__main__":
    df_mart, feature_cols, scalers = build_data_mart_v4()
    X, y_target, y_actual = create_sequences(df_mart, feature_cols)
    
    split = int(len(X) * 0.8)
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y_target[:split], y_target[split:]
    y_actual_test = y_actual[split:]

    experiment_name = "Samsung_Baseline_Improved_Regression"
    mlflow.set_experiment(experiment_name)

    print(f"\nğŸš€ {experiment_name} 30íšŒ ë°˜ë³µ ì‹¤í—˜ ì‹œì‘")
    
    roi_results = []
    trade_counts = [] # ê±°ë˜ íšŸìˆ˜ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€

    for seed in range(30):
        with mlflow.start_run(run_name=f"LogReg_Seed_{seed}"):
            tf.random.set_seed(seed)
            np.random.seed(seed)
            
            mlflow.log_param("seed", seed)
            
            model = build_lstm_regression((X_train.shape[1], X_train.shape[2]))
            model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=1, shuffle=False)
            
            pred_scaled = model.predict(X_test, verbose=1)
            pred_real = scalers['target_log_return'].inverse_transform(pred_scaled).flatten()
            
            # ì‹œë®¬ë ˆì´ì…˜
            balance = 10000000
            is_holding = False
            buy_count = 0 # ë§¤ìˆ˜ íšŸìˆ˜ ì´ˆê¸°í™”

            for i in range(len(pred_real) - 1):
                if is_holding: balance *= (1 + y_actual_test[i+1])
                
                if pred_real[i+1] > 0: # ë‚´ì¼ ìƒìŠ¹ ì˜ˆì¸¡ ì‹œ
                    if not is_holding:
                        is_holding = True
                        buy_count += 1 # ë§¤ìˆ˜ ì¹´ìš´íŠ¸ ì¦ê°€
                else:
                    is_holding = False
            
            final_roi = ((balance - 10000000) / 10000000) * 100
            roi_results.append(final_roi)
            trade_counts.append(buy_count) # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            
            mlflow.log_metric("final_roi", final_roi)
            mlflow.log_metric("buy_count", buy_count) # MLflow ê¸°ë¡
            
            print(f"â–¶ Seed {seed:2d} | ROI: {final_roi:6.2f}% | Trades: {buy_count:3d}íšŒ")

    # [ìµœì¢… ìš”ì•½ ì¶œë ¥]
    print("\n" + "="*60)
    print(f"ğŸ’° Baseline 30íšŒ í‰ê·  ìˆ˜ìµë¥  : {np.mean(roi_results):.2f}%")
    print(f"ğŸ“ˆ Baseline 30íšŒ í‰ê·  ê±°ë˜ íšŸìˆ˜: {np.mean(trade_counts):.1f}íšŒ")
    print("="*60)