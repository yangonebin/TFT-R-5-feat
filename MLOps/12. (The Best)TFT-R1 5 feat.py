import os
import yfinance as yf
import pandas as pd
import numpy as np
import warnings
import mlflow
import mlflow.keras
import tensorflow as tf
from tensorflow.keras import layers, Model, Input
from sklearn.preprocessing import StandardScaler
import time

# ìµœì í™” ë° ê²½ê³  ë¬´ì‹œ
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
warnings.filterwarnings('ignore')

# --- TFTë¥¼ ìœ„í•œ í•µì‹¬ ì»¤ìŠ¤í…€ ë¸”ë¡ ---
def gated_residual_network(x, units, dropout_rate=0.1):
    """ë¶ˆí•„ìš”í•œ ë¹„ì„ í˜•ì„±ì„ ì œì–´í•˜ëŠ” TFTì˜ í•µì‹¬ GRN ë¸”ë¡"""
    h = layers.Dense(units, activation='elu')(x)
    h = layers.Dense(units)(h)
    h = layers.Dropout(dropout_rate)(h)
    
    # Gated Linear Unit (GLU)
    gate = layers.Dense(units, activation='sigmoid')(x)
    x = layers.Add()([x, layers.Multiply()([gate, h])])
    return layers.LayerNormalization()(x)

# --- [ìˆ˜ì •ëœ VSN í•¨ìˆ˜] ---
def variable_selection_network(x, units, num_features):
    feature_embeddings = []
    for i in range(num_features):
        feat = layers.Lambda(lambda x, i=i: x[:, :, i:i+1])(x)
        feature_embeddings.append(layers.Dense(units)(feat))
        
    combined = layers.Concatenate()(feature_embeddings)
    weights = layers.Dense(num_features, activation='softmax')(combined)
    
    # tf.stackì„ Lambdaë¡œ ê°ì‹¸ì„œ ì‚¬ìš©
    stacked_features = layers.Lambda(lambda x: tf.stack(x, axis=2))(feature_embeddings)
    expanded_weights = layers.Reshape((-1, num_features, 1))(weights)
    weighted_features = layers.Multiply()([stacked_features, expanded_weights])
    
    return layers.Lambda(lambda x: tf.reduce_sum(x, axis=2))(weighted_features)

# --- ë°ì´í„° ë¹Œë” (5-Feature ì „ìš©) ---
def build_tft_data():
    target_stock = "005930.KS"
    df = yf.download(target_stock, period="max", auto_adjust=True, progress=False)
    if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
    
    df = df[['Open', 'High', 'Low', 'Close', 'Volume']].ffill().dropna()
    feature_cols = []
    for col in df.columns:
        new_name = f'Log_Ret_{col}'
        df[new_name] = np.log((df[col] + 1e-9) / (df[col].shift(1) + 1e-9))
        feature_cols.append(new_name)
    
    df['target_up'] = np.where(df['Close'].shift(-1) > df['Close'], 1, 0)
    df['actual_ret'] = (df['Close'].shift(-1) / df['Close']) - 1
    df = df.dropna()
    
    for col in feature_cols:
        df[col] = StandardScaler().fit_transform(df[[col]])
    return df, feature_cols

def create_sequences(df, features, window=20):
    X, y, r = [], [], []
    data, target, ret = df[features].values, df['target_up'].values, df['actual_ret'].values
    for i in range(len(df) - window):
        X.append(data[i:i+window])
        y.append(target[i+window-1])
        r.append(ret[i+window-1])
    return np.array(X), np.array(y), np.array(r)

def build_beast_tft(window_size, num_features, units=64):
    inputs = Input(shape=(window_size, num_features))
    
    # 1. Variable Selection (ì–´ë–¤ ê°€ê²© ì§€í‘œê°€ ì¤‘ìš”í•œê°€?)
    vsn = variable_selection_network(inputs, units, num_features)
    
    # 2. LSTM ê¸°ë°˜ì˜ Temporal Context ì¶”ì¶œ
    lstm = layers.LSTM(units, return_sequences=True)(vsn)
    lstm = layers.LayerNormalization()(lstm)
    
    # 3. Multi-Head Attention (ì‹œê³„ì—´ì˜ ì¥ë‹¨ê¸° ë§¥ë½ íŒŒì•…)
    attn = layers.MultiHeadAttention(num_heads=4, key_dim=units)(lstm, lstm)
    attn = layers.Add()([lstm, attn])
    attn = layers.LayerNormalization()(attn)
    
    # 4. Gated Residual Network (ìµœì¢… ì¶œë ¥ ì œì–´)
    grn = gated_residual_network(attn[:, -1, :], units)
    
    # 5. Output (Regressor: ìˆ˜ìµë¥  ê°•ë„ ì˜ˆì¸¡)
    outputs = layers.Dense(1)(grn) # V1ì²˜ëŸ¼ íšŒê·€ ëª¨ë¸ë¡œ ì„¤ì •
    
    model = Model(inputs, outputs)
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='mse')
    return model

# build_beast_tft ì•„í‚¤í…ì²˜ëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ë˜ ìœ„ vsn í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

if __name__ == "__main__":
    df, features = build_tft_data()
    X, y, r = create_sequences(df, features)
    
    split = int(len(X) * 0.8)
    X_train, X_test = X[:split], X[split:]
    # V1 ê³„ìŠ¹: ì‹¤ì œ ìˆ˜ìµë¥ (r)ë¡œ í•™ìŠµí•˜ëŠ” Regressor
    y_train, y_test = r[:split], r[split:] 
    r_test = r[split:]

    mlflow.set_experiment("Samsung_SOTA_TFT_5Features_Final")
    
    roi_results = []
    buy_counts = [] # <--- ë§¤ë§¤ íšŸìˆ˜ ì €ì¥ì„ ìœ„í•œ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
    
    print(f"\nğŸš€ [SOTA] TFT 5-Feature ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦ ì‹œì‘")
    print("="*60)

    for seed in range(30):
        with mlflow.start_run(run_name=f"TFT_Seed_{seed}"):
            tf.random.set_seed(seed)
            np.random.seed(seed)
            mlflow.log_param("seed", seed)
            
            model = build_beast_tft(X.shape[1], X.shape[2])
            es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)
            
            model.fit(X_train, y_train, validation_data=(X_test, y_test), 
                      epochs=150, batch_size=128, verbose=0, callbacks=[es])
            
            preds = model.predict(X_test, verbose=0).flatten()
            
            # ì‹œë®¬ë ˆì´ì…˜
            balance = 10000000
            buy_count = 0
            for i in range(len(preds)):
                if preds[i] > 0: 
                    balance *= (1 + r_test[i])
                    buy_count += 1
            
            final_roi = ((balance - 10000000) / 10000000) * 100
            
            # ê²°ê³¼ ì €ì¥
            roi_results.append(final_roi)
            buy_counts.append(buy_count) # <--- ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            
            mlflow.log_metric("final_roi", final_roi)
            mlflow.log_metric("buy_count", buy_count)
            
            print(f"[{time.strftime('%H:%M:%S')}] Seed {seed:2d} | ROI: {final_roi:8.2f}% | Buy: {buy_count:4d}")

    # --- ìµœì¢… ê²°ê³¼ ì¶œë ¥ ì„¹ì…˜ ---
    print("\n" + "="*60)
    print(f"ğŸ† [TFT SOTA ìµœì¢… ë¦¬í¬íŠ¸]")
    print(f" - 30íšŒ í‰ê·  ROI: {np.mean(roi_results):.4f}%")
    print(f" - 30íšŒ í‰ê·  ë§¤ë§¤ íšŸìˆ˜: {np.mean(buy_counts):.2f}íšŒ") # <--- ìš”ì²­í•˜ì‹  ë¶€ë¶„
    print(f" - ìµœê³  ROI (Seed {np.argmax(roi_results)}): {np.max(roi_results):.2f}%")
    print("="*60)