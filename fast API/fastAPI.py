import os
import yfinance as yf
import pandas as pd
import numpy as np
import tensorflow as tf
import joblib
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from tensorflow.keras import layers, Model, Input
from contextlib import asynccontextmanager

# --- [ 1. í™˜ê²½ ì„¤ì • ] ---
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
SEED = 22

# --- [ 2. ì•„í‚¤í…ì²˜ ì •ì˜ (ë¹ˆ ëª¨ë¸ ìƒì„±ìš©) ] ---

def variable_selection_network(x, units, num_features):
    feature_embeddings = []
    for i in range(num_features):
        # ì—¬ê¸°ê°€ ì—ëŸ¬ì˜ ì›ì¸ì´ì—ˆë˜ Lambda ë¶€ë¶„ì…ë‹ˆë‹¤.
        # ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œí•  ë•ŒëŠ” ì´ ì½”ë“œê°€ ìƒˆë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤.
        feat = layers.Lambda(lambda t: t[:, :, i:i+1])(x)
        feature_embeddings.append(layers.Dense(units)(feat))
        
    combined = layers.Concatenate()(feature_embeddings)
    weights = layers.Dense(num_features, activation='softmax')(combined)
    
    stacked_features = layers.Lambda(lambda x: tf.stack(x, axis=2))(feature_embeddings)
    expanded_weights = layers.Reshape((-1, num_features, 1))(weights)
    weighted_features = layers.Multiply()([stacked_features, expanded_weights])
    
    return layers.Lambda(lambda x: tf.reduce_sum(x, axis=2))(weighted_features)

def gated_residual_network(x, units, dropout_rate=0.1):
    h = layers.Dense(units, activation='elu')(x)
    h = layers.Dense(units)(h)
    h = layers.Dropout(dropout_rate)(h)
    gate = layers.Dense(units, activation='sigmoid')(x)
    x = layers.Add()([x, layers.Multiply()([gate, h])])
    return layers.LayerNormalization()(x)

def build_beast_tft(window_size, num_features, units=64):
    inputs = Input(shape=(window_size, num_features))
    vsn = variable_selection_network(inputs, units, num_features)
    lstm = layers.LSTM(units, return_sequences=True)(vsn)
    lstm = layers.LayerNormalization()(lstm)
    attn = layers.MultiHeadAttention(num_heads=4, key_dim=units)(lstm, lstm)
    attn = layers.Add()([lstm, attn])
    attn = layers.LayerNormalization()(attn)
    grn = gated_residual_network(attn[:, -1, :], units)
    outputs = layers.Dense(1)(grn) 
    model = Model(inputs, outputs)
    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='mse')
    return model

# --- [ 3. Lifespan ì„¤ì • (í•µì‹¬ ë³€ê²½!) ] ---
model = None
scaler = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global model, scaler
    print("ğŸ”‹ ë¡œë”© ì¤‘: Beast V3 ëª¨ë¸ êµ¬ì¡° ìƒì„± ë° ê°€ì¤‘ì¹˜ ì£¼ì…...")
    try:
        scaler = joblib.load('beast_scaler.pkl')
        
        # 1. ë¹ˆ ëª¨ë¸(ê»ë°ê¸°)ì„ ë¨¼ì € ë§Œë“­ë‹ˆë‹¤. (ì…ë ¥ í¬ê¸°: 20ì¼, 5ê°œ í”¼ì²˜)
        model = build_beast_tft(window_size=20, num_features=5)
        
        # 2. ì €ì¥ëœ íŒŒì¼ì—ì„œ 'ê°€ì¤‘ì¹˜(Weights)'ë§Œ ì™ ë¹¼ì™€ì„œ ë®ì–´ì”Œì›ë‹ˆë‹¤.
        # by_name=True ì˜µì…˜ìœ¼ë¡œ ì´ë¦„ì´ ë§ëŠ” ì¸µë¼ë¦¬ ë§¤ì¹­í•´ ì—ëŸ¬ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
        model.load_weights('beast_tft_full.h5')
        
        print("ğŸš€ Beast V3 ì—”ì§„ ê°€ë™ ì¤€ë¹„ ì™„ë£Œ (Seed 22)")
    except Exception as e:
        print(f"âŒ ë¡œë”© ì‹¤íŒ¨ ì—ëŸ¬: {e}")
        print("ğŸ’¡ íŒ: ëª¨ë¸ ì•„í‚¤í…ì²˜ê°€ í•™ìŠµ ì½”ë“œì™€ ì™„ì „íˆ ë™ì¼í•œì§€ í™•ì¸í•˜ì„¸ìš”.")
    yield

# --- [ 4. FastAPI ì•± ì„¤ì • ] ---
app = FastAPI(title="Beast V3: SSAFY Edition", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/predict")
def predict_stock():
    if model is None or scaler is None:
        return {"status": "error", "message": "Model not loaded"}
        
    target_stock = "005930.KS"
    # period="1mo"ë¡œ ë„‰ë„‰í•˜ê²Œ ê°€ì ¸ì™€ì•¼ 21ê°œ ì´ìƒ í™•ë³´ ê°€ëŠ¥
    df = yf.download(target_stock, period="1mo", auto_adjust=True, progress=False)
    if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
    
    data = df[['Open', 'High', 'Low', 'Close', 'Volume']].tail(21).copy()
    feature_cols = []
    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
        name = f'Log_Ret_{col}'
        data[name] = np.log((data[col] + 1e-9) / (data[col].shift(1) + 1e-9))
        feature_cols.append(name)
    
    data = data.dropna()
    
    # ë°ì´í„° ê°œìˆ˜ ì²´í¬ (20ê°œ ë¯¸ë§Œì´ë©´ ì—ëŸ¬ ë°©ì§€)
    if len(data) < 20:
        return {"status": "error", "message": "Not enough data fetched from Yahoo Finance"}

    input_scaled = scaler.transform(data[feature_cols])
    input_seq = np.expand_dims(input_scaled, axis=0)
    
    # ì¶”ë¡ 
    prediction = float(model.predict(input_seq, verbose=0)[0][0])
    
    return {
        "status": "success",
        "result": {
            "predicted_return": f"{prediction * 100:.4f}%",
            "signal": "BUY" if prediction > 0 else "HOLD"
        },
        "meta": {
            "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
        }
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)